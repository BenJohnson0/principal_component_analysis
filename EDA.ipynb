{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "Ben Johnson X00229603 - https://youtu.be/HAO4wzl6y4I"
      ],
      "metadata": {
        "id": "aJ463yVJNOt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "TW10iqvAI8A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "df = pd.read_csv('CA2_data.csv')"
      ],
      "metadata": {
        "id": "3BVm1yumJXF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data head\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "yzx8zrE2KQaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic df information\n",
        "df.info()"
      ],
      "metadata": {
        "id": "oDO2bHhnLqcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "lIVIkqGoLqZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check datatypes\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "ie-t5oJvMfNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe numerical data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "84SJ_TdNLqXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe categorical data\n",
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "iLZyh_W7LqU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for nulls\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "2HvMcukpLqSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "zkDJNBodLqP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for column name issues\n",
        "df.columns"
      ],
      "metadata": {
        "id": "MUcRd5xFLqNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigating \"EmployeeCount\"\n",
        "We can drop EmployeeCount as each entry already represents 1 employee. In short, this is duplicated data."
      ],
      "metadata": {
        "id": "q_bDiawiOHdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.EmployeeCount.value_counts()"
      ],
      "metadata": {
        "id": "eDmjUwqMOKdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('EmployeeCount', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ffFULAyVOOvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigating \"StandardHours\"\n",
        "All entries are \"80\", so we can drop this column to reduce dimensionality."
      ],
      "metadata": {
        "id": "Z2hh4kPHOTnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.StandardHours.value_counts()"
      ],
      "metadata": {
        "id": "KNhGYZ9ZOY6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('StandardHours', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "UBK-FRbBOc1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "0tC_0jEwCrED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigating \"MonthlyIncome\", \"MonthlyRate\" & \"DailyRate\"\n",
        "The first two columns are identified as categorical because they are strings. We will convert the values to integers before handling the data. The columns have 1350 &\t1427 unique entries respectively.\n",
        "\n",
        "The DailyRate column will also be binned for simplicity & understandability."
      ],
      "metadata": {
        "id": "eWzGIV8h4sze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting columns to numerical\n",
        "df['MonthlyIncome'] = pd.to_numeric(df['MonthlyIncome'], errors='coerce')\n",
        "df['MonthlyRate'] = pd.to_numeric(df['MonthlyRate'], errors='coerce')"
      ],
      "metadata": {
        "id": "R5tgFD9C5KZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MonthlyIncome'].describe()"
      ],
      "metadata": {
        "id": "8RBiB6bH8xmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MonthlyRate'].describe()"
      ],
      "metadata": {
        "id": "EXhReevT84Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using quantile-based binning for MonthlyIncome\n",
        "num_bins = 5\n",
        "\n",
        "df['MonthlyIncome_Binned'] = pd.qcut(df['MonthlyIncome'], q=num_bins, labels=False)\n",
        "\n",
        "df = df.drop('MonthlyIncome', axis=1)"
      ],
      "metadata": {
        "id": "OeA3jEb47yYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using quantile-based binning for MonthlyRate\n",
        "num_bins = 5\n",
        "\n",
        "df['MonthlyRate_Binned'] = pd.qcut(df['MonthlyRate'], q=num_bins, labels=False)\n",
        "\n",
        "df = df.drop('MonthlyRate', axis=1)"
      ],
      "metadata": {
        "id": "9YQOQEEj5KWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "qEG5kujI9rZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop first row due to binned NaN\n",
        "df = df.drop(df.index[0])"
      ],
      "metadata": {
        "id": "-3JZLqPPBNCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using quantile-based binning for DailyRate\n",
        "num_bins = 5\n",
        "\n",
        "df['DailyRate_Binned'] = pd.qcut(df['DailyRate'], q=num_bins, labels=False)\n",
        "\n",
        "df = df.drop('DailyRate', axis=1)"
      ],
      "metadata": {
        "id": "yFczpxlmB96D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "rOuSW7yMBWDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Addressing multi-collinearity"
      ],
      "metadata": {
        "id": "hqUpqW7lEHtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Square Test"
      ],
      "metadata": {
        "id": "LlJmtQXXFDdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# apply Chi-Square Test\n",
        "X = df.drop(columns=['Attrition'])\n",
        "y = df['Attrition'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "chi2_selector = SelectKBest(chi2, k=12)\n",
        "chi2_selector.fit(X.select_dtypes(include=['int64', 'float64']), y)\n",
        "\n",
        "selected_features = X.select_dtypes(include=['int64', 'float64']).columns[chi2_selector.get_support()]\n",
        "print(\"Top features based on Chi-Square Test:\", selected_features)"
      ],
      "metadata": {
        "id": "d5ZoxNUNEHg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation values for numerical features"
      ],
      "metadata": {
        "id": "vyB5lvCXFKNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "numerical_df = df.select_dtypes(include=np.number)\n",
        "\n",
        "corr_matrix = numerical_df.corr()\n",
        "\n",
        "print(corr_matrix['Attrition'].abs().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "x3-wCJCtE1HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "significant_features = {}\n",
        "for col in numerical_df.columns:\n",
        "    if col != 'Attrition':\n",
        "        r, p_value = pearsonr(numerical_df[col], numerical_df['Attrition'])\n",
        "        significant_features[col] = (r, p_value)\n",
        "\n",
        "significant_features = {k: v for k, v in significant_features.items() if v[1] < 0.05}\n",
        "significant_features"
      ],
      "metadata": {
        "id": "L6R1wem5sr_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selected Features Based on Chi-Square Test and Correlation Analysis\n",
        "The following features display moderate correlation with attrition or were identified by the Chi-Square test as important contributors to the predictive power of the model:\n",
        "\n",
        "\n",
        "| Feature                 | Correlation with Attrition | Source                  |\n",
        "|-------------------------|----------------------------|-------------------------|\n",
        "| MonthlyIncome_Binned    | 0.188696                  | Correlation Analysis    |\n",
        "| TotalWorkingYears       | 0.170721                  | Correlation Analysis    |\n",
        "| JobLevel                | 0.169315                  | Both                   |\n",
        "| YearsInCurrentRole      | 0.160732                  | Correlation Analysis    |\n",
        "| Age                     | 0.160193                  | Both                   |\n",
        "| YearsWithCurrManager    | 0.156862                  | Correlation Analysis    |\n",
        "| StockOptionLevel        | 0.135979                  | Both                   |\n",
        "| YearsAtCompany          | 0.134376                  | Both                   |\n",
        "| JobInvolvement          | 0.130844                  | Correlation Analysis    |\n",
        "| DistanceFromHome        | N/A                       | Chi-Square Test         |\n",
        "| YearsSinceLastPromotion | N/A                       | Chi-Square Test         |\n",
        "| DailyRate_Binned        | N/A                       | Chi-Square Test         |\n",
        "| TrainingTimesLastYear        | 0.056295                       | Both         |\n",
        "| RelationshipSatisfaction        | 0.043527                       | Correlation Analysis      |\n",
        "| NumCompaniesWorked        | 0.040327                       | Correlation Analysis        |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kSflkNCRtINt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce dataset to these identified features\n",
        "selected_features = [\n",
        "    \"MonthlyIncome_Binned\",\n",
        "    \"TotalWorkingYears\",\n",
        "    \"JobLevel\",\n",
        "    \"YearsInCurrentRole\",\n",
        "    \"Age\",\n",
        "    \"YearsWithCurrManager\",\n",
        "    \"StockOptionLevel\",\n",
        "    \"YearsAtCompany\",\n",
        "    \"JobInvolvement\",\n",
        "    \"DistanceFromHome\",\n",
        "    \"YearsSinceLastPromotion\",\n",
        "    \"DailyRate_Binned\",\n",
        "    \"TrainingTimesLastYear\",\n",
        "    \"RelationshipSatisfaction\",\n",
        "    \"NumCompaniesWorked\"\n",
        "]\n",
        "\n",
        "df = df[selected_features + ['Attrition']]"
      ],
      "metadata": {
        "id": "1wma-mcFvEqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "FOHTudQSvVys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualisation"
      ],
      "metadata": {
        "id": "qGOhC-GkNXXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attrition Distribution"
      ],
      "metadata": {
        "id": "SWz25hCMVcMk"
      }
    },
    {
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=\"Attrition\", data=df, palette=\"viridis\")\n",
        "plt.title(\"Attrition Distribution\")\n",
        "plt.xlabel(\"Attrition\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "n0rLHzAbxJ1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Age vs. Attrition"
      ],
      "metadata": {
        "id": "PeAZGwagCUeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x=\"Attrition\", y=\"Age\", data=df, palette=\"coolwarm\")\n",
        "plt.title(\"Age vs. Attrition\")\n",
        "plt.xlabel(\"Attrition\")\n",
        "plt.ylabel(\"Age\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gb1IUMx3LqK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monthly Income vs. Job Level"
      ],
      "metadata": {
        "id": "kmS05--VCX44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x=\"JobLevel\", y=\"MonthlyIncome_Binned\", data=df, palette=\"muted\")\n",
        "plt.title(\"Monthly Income vs. Job Level\")\n",
        "plt.xlabel(\"Job Level\")\n",
        "plt.ylabel(\"Monthly Income (Binned)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbmuInHVNxcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Years at Company vs. Attrition"
      ],
      "metadata": {
        "id": "dRjkJ4ByCdvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.kdeplot(data=df[df[\"Attrition\"] == 0], x=\"YearsAtCompany\", fill=True, label=\"Stayed\", color=\"green\")\n",
        "sns.kdeplot(data=df[df[\"Attrition\"] == 1], x=\"YearsAtCompany\", fill=True, label=\"Left\", color=\"red\")\n",
        "plt.title(\"Years at Company vs. Attrition\")\n",
        "plt.xlabel(\"Years at Company\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IjW0cSCTNxSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship Satisfaction vs. Attrition"
      ],
      "metadata": {
        "id": "eHYuHDOIVpd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=\"RelationshipSatisfaction\", hue=\"Attrition\", data=df, palette=\"pastel\")\n",
        "plt.title(\"Relationship Satisfaction vs. Attrition\")\n",
        "plt.xlabel(\"Relationship Satisfaction\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend(title=\"Attrition\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x6aVtKHkwu3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance from Home vs. Attrition"
      ],
      "metadata": {
        "id": "dGo69Rr-VuXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.stripplot(x=\"Attrition\", y=\"DistanceFromHome\", data=df, jitter=True, palette=\"Set2\", alpha=0.7)\n",
        "plt.title(\"Distance from Home vs. Attrition\")\n",
        "plt.xlabel(\"Attrition\")\n",
        "plt.ylabel(\"Distance from Home\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vIT9lGclVwsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fairness Investigation"
      ],
      "metadata": {
        "id": "3tU6WiN6NdSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zNZTlfmGNI6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import widgets\n",
        "from IPython.core.display import display, HTML\n",
        "import base64\n",
        "!pip install tensorflow==2.15.1\n",
        "!pip install facets-overview==1.1.1\n",
        "from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator"
      ],
      "metadata": {
        "id": "ZrcoeDjHLqId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsg = FeatureStatisticsGenerator()\n",
        "dataframes = [\n",
        "    {'table': train_df, 'name': 'trainData'}]\n",
        "censusProto = fsg.ProtoFromDataFrames(dataframes)\n",
        "protostr = base64.b64encode(censusProto.SerializeToString()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
        "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
        "        <facets-overview id=\"elem\"></facets-overview>\n",
        "        <script>\n",
        "          document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n",
        "        </script>\"\"\"\n",
        "html = HTML_TEMPLATE.format(protostr=protostr)\n",
        "display(HTML(html))"
      ],
      "metadata": {
        "id": "wZHr_LFpM--W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 1175\n",
        "\n",
        "train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')\n",
        "\n",
        "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
        "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
        "        <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n",
        "        <script>\n",
        "          var data = {jsonstr};\n",
        "          document.querySelector(\"#elem\").data = data;\n",
        "        </script>\"\"\"\n",
        "html = HTML_TEMPLATE.format(jsonstr=train_dive)\n",
        "display(HTML(html))"
      ],
      "metadata": {
        "id": "0Iztmn0WM-5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Analysis"
      ],
      "metadata": {
        "id": "mg7YbDMuNn1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Matrix"
      ],
      "metadata": {
        "id": "-VYLahJ7bWeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix\n",
        "corr = df.select_dtypes(include=np.number).corr()\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, cmap='viridis', center=0)\n",
        "plt.title('Feature Correlations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fFSPnlThNxOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping columns based on correlation matrix\n",
        "df = df.drop(columns=[\"YearsSinceLastPromotion\", \"DailyRate_Binned\", \"TrainingTimesLastYear\", \"RelationshipSatisfaction\"])"
      ],
      "metadata": {
        "id": "6u_xyhh9ZxZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latest df\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "ZSR1FI15aDkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "M5UqGhUmbY0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "jxpS7_WvbBQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select and scale only numeric features\n",
        "df_numeric = df.select_dtypes(include=np.number)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_numeric)"
      ],
      "metadata": {
        "id": "pwsdHpVhbcP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the PCA model to the scaled data and transform it\n",
        "pca = PCA()\n",
        "pca_components = pca.fit_transform(df_scaled)"
      ],
      "metadata": {
        "id": "gmzhMzdjbcNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the cumulative explained variance ratio\n",
        "explained_variance = np.cumsum(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "NwSDh-PfbcHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot cumulative explained variance to determine the optimal number of features\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Explained Variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3xMH_P2ecD0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PCA Explained Variance Diagram is showing diminishing returns after the 9th or 10th component, where >95% of variance is explained. We can try a hypothesis test and MLR in order to identify the final feature to remove."
      ],
      "metadata": {
        "id": "stw0W8QbBHit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis testing"
      ],
      "metadata": {
        "id": "TsIsq6YdcRxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-way ANOVA test for weak explanatory variables\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "continuous_vars = ['NumCompaniesWorked', \"TotalWorkingYears\"]\n",
        "for var in continuous_vars:\n",
        "    groups = [group[var].values for name, group in df.groupby('Attrition')]\n",
        "    f_stat, p_value = f_oneway(*groups)\n",
        "    print(f\"ANOVA test for {var}: p-value={p_value}\")"
      ],
      "metadata": {
        "id": "ykhRhAOAcT0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression"
      ],
      "metadata": {
        "id": "_nw4jJ_4cgS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "qh9kz4D6cjH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop target variable\n",
        "X = df.drop(['Attrition'], axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "0LkDZO0Mcjpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all columns in X to numeric and drop NaNs\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "iLDJu0u2c6mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# align target variable with the rows in the feature matrix X\n",
        "y = df['Attrition']\n",
        "y = y[X.index]"
      ],
      "metadata": {
        "id": "YwG6iG-Jc7qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a constant\n",
        "X = sm.add_constant(X)"
      ],
      "metadata": {
        "id": "KC6YW0rtcjnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identify boolean columns\n",
        "bool_cols = X.select_dtypes(include=['bool']).columns\n",
        "print(\"Boolean columns:\", bool_cols)"
      ],
      "metadata": {
        "id": "UyVVVaBGdThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert boolean values to integers\n",
        "X[bool_cols] = X[bool_cols].astype(int)"
      ],
      "metadata": {
        "id": "mrZtOCENdc85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run OLS model\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "bmx-EWeNcpFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TotalWorkingYears was removed from the model because its p-value (0.354) in the OLS regression results indicates it is not statistically significant at the common threshold of 0.05. This suggests that TotalWorkingYears does not provide meaningful explanatory power for predicting Attrition when other variables are accounted for."
      ],
      "metadata": {
        "id": "3O_PCuLuB4Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify statistically significant variables based on p-values\n",
        "significant_vars = model.pvalues[model.pvalues < 0.05].index.tolist()"
      ],
      "metadata": {
        "id": "iQJFDvY8cqJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick look\n",
        "significant_vars.remove('const')\n",
        "significant_vars"
      ],
      "metadata": {
        "id": "mTZm6J8IcMil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop TotalWorkingYears\n",
        "df = df.drop('TotalWorkingYears', axis=1)"
      ],
      "metadata": {
        "id": "-zEI8w44be3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final dataframe\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "xQiCalGWbjAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting df as CSV (uncomment if needed)\n",
        "# df.to_csv('JohnsonCA2.csv', index=False)"
      ],
      "metadata": {
        "id": "jxwhp0ugbwe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing"
      ],
      "metadata": {
        "id": "kW9FNKc-NqwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# load the Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "-wJ1UQ48LqDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images are classified as follows:\n",
        "\n",
        "*   0 T-shirt/top\n",
        "*   1 Trouser\n",
        "*   2 Pullover\n",
        "*   3 Dress\n",
        "*   4 Coat\n",
        "*   5 Sandal\n",
        "*   6 Shirt\n",
        "*   7 Sneaker\n",
        "*   8 Bag\n",
        "*   9 Ankle boot\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rpv6kU4_D5FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create array of types\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "ztZnoomXC9XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show some examples of what we are working with\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P34YCbYBC9zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "TeanzAbeFcL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "axHzTYeGE8og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize images\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "uXCyfyqCE8mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15, # randomly rotate in range 15 degrees\n",
        "    width_shift_range=0.1, # randomly shifts images horizontally up to 10% of the width\n",
        "    height_shift_range=0.1, # randomly shifts images vertically up to 10% of the height\n",
        "    shear_range=0.1, # applies random shearing transformations up to 10 degrees\n",
        "    zoom_range=0.1, # randomly zooms images in or out by up to 10%\n",
        "    featurewise_center=True, # normalizes the dataset by subtracting the mean value of the training set\n",
        "    featurewise_std_normalization=True, # normalizes the dataset by dividing by the standard deviation of the training set\n",
        "    horizontal_flip=False # prevents flipping the image horizontally, important for non-symmetrical data like Fashion-MNIST\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "xOi75lVjE8kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize augmented data\n",
        "augmented_images, augmented_labels = next(datagen.flow(x_train, y_train, batch_size=9))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(augmented_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[augmented_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZpBbyNTE8hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dimensionality Reduction using PCA"
      ],
      "metadata": {
        "id": "hbdqoqX-FXdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import cv2"
      ],
      "metadata": {
        "id": "stvgGMQaE8fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten images\n",
        "x_train_flat = x_train.reshape(-1, 28*28)"
      ],
      "metadata": {
        "id": "qQqei15bE8cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply PCA\n",
        "pca = PCA(n_components=40)\n",
        "x_train_pca = pca.fit_transform(x_train_flat)"
      ],
      "metadata": {
        "id": "o6clMk4lE8aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize PCA results\n",
        "plt.figure(figsize=(8, 8))\n",
        "scatter = plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1],\n",
        "                      c=y_train, cmap='tab10', s=2)\n",
        "plt.colorbar(scatter, ticks=range(10), label=\"Class\")\n",
        "plt.title(\"PCA of Fashion-MNIST\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0YNL1WYzE8Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA helps reduce dimensionality while preserving variance. However, the overlap of colours, which are classes, suggests that PCA in 2D may not completely separate the classes. This indicates that the dataset has inherent overlap in feature space, making it challenging to linearly separate classes with only two principal components."
      ],
      "metadata": {
        "id": "0ZpaIMUSEcmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# diagram of explained variance fro PCA\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.title(\"PCA: Cumulative Explained Variance\")\n",
        "plt.xlabel(\"Number of Principal Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e1X36WFdE8VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A significant reduction in dimensionality is achievable with PCA. For example, instead of using the original high-dimensional space, 40 components retain most of the information (>85% variance). Using fewer components can speed up machine learning models without losing much predictive power."
      ],
      "metadata": {
        "id": "0kGC38WWEo8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(x_train_pca[:2000])\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "scatter = plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=y_train[:2000], cmap='tab10', s=10)\n",
        "plt.colorbar(scatter)\n",
        "plt.title(\"t-SNE Visualization of Fashion-MNIST\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sixHZZS8Fc_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-SNE is non-linear, and excels at capturing local structures, making it more suitable for visualizing complex datasets like Fashion-MNIST. t-SNE is better than PCA for visualizing separability and relationships among classes in lower dimensions.\n",
        "\n",
        "Some clusters are more distinct; class 1 for example, compared to others, suggesting that certain classes are inherently more separable. Despite clearer separation, some overlap between certain classes still exists, indicating potential similarity or ambiguity in their features. This overlap is not all bad, as classes 5, 7, and 9 are out on their own, they are all footwear, which was successfully captured by t-SNE.\n",
        "\n",
        "Similarly, the orange cluster at the bottom are trousers, and the slim yellow cluster at the top are bags!"
      ],
      "metadata": {
        "id": "pQtSHqvJEDpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert"
      ],
      "metadata": {
        "id": "yvpzjV57Tz9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert /content/JohnsonCA2.ipynb --to html"
      ],
      "metadata": {
        "id": "sZ2kW_IqT2P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}